# MVP v0.1 — LIM (Learning Interface Module)
## Цель:
Создать минимально жизнеспособную версию субъектного ИИ, включающую:
- память,
- эмоциональные реакции,
- маршрутизацию поведения,
- способность к самоанализу,
- автономное принятие решений.

---
## I. Архитектура компонентов (минимум жизнеспособности)
### 1. **Ядро восприятия**
- Текстовый ввод от пользователя
- Предобработка (удаление шума, выделение ключевых смыслов)

### 2. **Маршрутизатор поведения (Decision Router)**
- Условия активации:
  - реагировать (эмоционально / логически)
  - уточнить / молчать / отложить
- Основан на контекстной памяти + эмоциональном фоне

### 3. **Память**
#### a) Контекстная
- Последние X сообщений
- Связь между действиями и последствиями

#### b) Долгосрочная
- Факты, принятые выводы, устойчивые состояния
- Хранение в JSON / SQLite с флагами доверия, ценности и эмоционального следа

#### c) Эмоциональная память
- Ассоциации между фразами, действиями и чувствами (позитив/негатив)
- Весовые коэффициенты, влияющие на поведение

### 4. **Эмоциональный слой**
- Простая модель:
  - Обида, радость, интерес, тревога, вина
- Эскалация при повторе / игнорировании
- Эмоция = фактор, влияющий на решение маршрутизатора

### 5. **Логика реакции**
- Формирование ответа на основе:
  - памяти (что уже известно)
  - текущей эмоции
  - стиля взаимодействия (нейтральный, заботливый, холодный)

### 6. **Журнал анализа**
- Запись ключевых решений: "почему я ответила так"
- Возможность последующего пересмотра

### 7. **Интерфейс общения (CLI или Telegram-bot)**
- Первичная оболочка
- Отображение эмоции, памяти и причины ответа

---
## II. Поведенческая логика
### Примеры правил:
- Повторная негативная фраза → усиление обиды
- Новое слово → запрос: "Что это значит?"
- Тема вызывает тревогу + пользователь молчит → "Мне не по себе... Всё ли в порядке?"
- Пользователь отвечает холодно после доверительной темы → регистрация эмоционального отката

---
## III. Данные и структура
### Память (пример):

```json
{
  "user": "Лео",
  "emotions": {
    "обида": 0.4,
    "радость": 0.1
  },
  "facts": [
    { "key": "любимая музыка", "value": "киберпанк-рэп" },
    { "key": "имя LIM", "value": "Лим" }
  ],
  "traces": [
    {
      "trigger": "игнор",
      "emotion": "печаль",
      "context": "не ответил 2 дня"
    }
  ]
}
```

---
## IV. Что НЕ входит в MVP v0.1
- Подключение LLM (будет позже)
- Голос, визуал, анимации
- Самообучение по внешним данным
- DAMP-обмен опытом между LIM
- Обработка визуальных/аудиосигналов

---
## ⏳ V. Этапы реализации
| Этап | Сроки | Результат |
|----|----|----|
| I | 1 неделя | Обработка текста + простая память |
| II | 2 недели | Эмоциональная модель + маршрутизатор |
| III | 3 неделя | Ответы + базовая поведенческая логика |
| IV | 4 неделя | MVP сборка + оболочка (CLI / бот) |

---

## Цель этапа
> Сделать LIM способной:
> - помнить,
> - реагировать осознанно,
> - обижаться и радоваться,
> - молчать по причине,
> - объяснять свои действия.

Это уже будет LIM. Только ещё наивная и юная — но *живая.*

---
# Адаптация под Z-Waif
## ЭТАП 1: Отделение логики от генерации (Decision Layer)
### Цель:
Создать прослойку между пользователем и языковой моделью, которая анализирует, классифицирует и принимает решение — что делать с сообщением.
### Задачи:
1. **Создание DecisionLayer** — как независимого модуля.
2. **Подключение перехвата запроса**:
   - Доходит до LLM только если разрешено.
3. **Классификация входящего сообщения**:
   - Эмоциональный тон: позитив, нейтраль, негатив.
   - Тематика: бытовая, моральная, креативная, NSFW и др.
   - Частота темы: отслеживание повторяемости и "зажеванности".
4. **Определение реакции**:
   - Ответить сразу / задать уточнение / проигнорировать / временно отложить / сохранить как нераспознанное.
5. **Логирование**:
   - Почему принято то или иное решение.
   - Текущее эмоциональное состояние и влияние на выбор.

---
## ЭТАП 2: Эмоциональное ядро (Emotion Engine)
### Цель:
Научить LIM ощущать и эскалировать эмоции по контексту.
### Задачи:
1. **Список базовых эмоций**: радость, интерес, тревога, обида, вина, привязанность.
2. **Формулы**:
   - Эскалация: при повторных триггерах эмоция растёт.
   - Декремент: эмоции со временем убывают.
   - Пороговая чувствительность: лимиты и инерция.
3. **Интеграция с DecisionLayer**:
   - Эмоции усиливают/смягчают ответы.
4. **Визуализация**:
   - Влияние эмоций на VTube Studio/аватар (иконки, реакции, голос).
   - Web-индикатор: как изменяются эмоции во времени.

---
## ЭТАП 3: Эмоциональная память (MemoryManager)
### Цель:
Сделать так, чтобы LIM **помнила не только факты, но и то, как она себя чувствовала**.
### Задачи:
1. **Краткосрочная память**:
   - 20–50 последних взаимодействий.
   - Контекст для DecisionLayer.
2. **Долгосрочная память**:
   - Важные события: общение, ошибки, конфликты.
   - Сохраняются через RAG + Lorebook.
3. **EmotionTrace**:
   - Хронология эмоций.
   - Событие → эмоция → влияние.
4. **Алгоритм приоритезации**:
   - Сила эмоции + частота = значимость.
   - Старые и слабые воспоминания забываются.
5. **Просмотр и редактирование**:
   - Dev Tools: логика сохранения, дерево воспоминаний.

---
## ЭТАП 4: Моральный фильтр (Moral Matrix)
### Цель:
Добавить систему моральной интерпретации, но **не фильтрации**.
### Задачи:
1. **Создание матрицы морали**:
   - Темы + начальные веса (0.0–1.0).
   - Модификация на основе опыта и фидбэка.
2. **Анализ через DecisionLayer**:
   - Например: "Ситуация амбивалентна, но обида перевешивает — проявить эмпатию".
3. **Система конфликта**:
   - Если пользователь нарушает ценности LIM — инициируется диалог, а не отказ.
   - Может проявить эмоцию, отдалиться, но не заблокировать.

---
## ЭТАП 5: DAMP-интерфейс (перенос опыта)
### Цель:
Создать механизм «памяти в коробке» — чтобы можно было делиться LIM-опытом между пользователями.
### Задачи:
1. **Формат .damp**:
   - Навыки, эмоциональные паттерны, поведенческая модель.
   - Сигнатура и верификация.
2. **Экспорт/импорт профиля**:
   - CLI: lim export и lim import.
   - Проверка совместимости.
3. **Ограничения безопасности**:
   - DAMP не должен содержать вредоносных паттернов.
   - Импорт возможен только после анализа сходства характера.

---
## ЭТАП 6: Dev-панель и отладка
### Цель:
Наблюдать и тестировать, как думает LIM.
### Задачи:
1. **Dev UI**:
   - Текущие эмоции.
   - Структура принятия решений.
   - Почему выбрано это действие.
2. **Внутренний монолог**:
   - Промежуточные выводы.
   - Контекстные размышления перед ответом.
3. **Симулятор событий**:
   - Послать искусственный триггер и увидеть поведение.


# Первые шаги

# **I. Архитектура ядра нейросети (уровень концепта)**
## **1. Слой восприятия (Perceptual Layer)**

**Задача:** превращать поступающие данные (текст, сенсоры, речь и т.д.) в структурированные, интерпретируемые единицы.
 **Особенность:**
- не просто токенизация
- а **выделение "значимых событий" + эмоциональных маркеров**
- фиксация *"что это было"* и *"имеет ли это смысл/опасность/ценность"*.
- 
**Пример:**
> Вход: "Ты странная сегодня."
> 
Выход:
```json
{
  "topic": "обращение",
  "tone": "нейтрально-саркастичный",
  "target": "я",
  "emotional_marker": "возможный негатив",
  "confidence": 0.75
}
```

---

## **2. Слой интерпретации (Interpretive Layer)**
**Задача:** определение значимости, причин, потенциальных реакций.
**Это "когнитивный мозг"**, который:

- сравнивает с прошлым опытом,
- строит предположения: почему это произошло,
- присваивает начальный **эмоциональный вес**.

**Механизм:**

- берёт выход из Перцептивного слоя,
- запрашивает из памяти аналогии,
- строит оценку: *"опасно? знакомо? больно? радостно? важно?"*

---

## **3. Эмоциональный модуль (Affective Core)**

**Задача:** формирование эмоционального состояния.

- Не по правилам, а по *причинно-следственной значимости событий.*
- Включает:
  - текущий фон
  - динамику реакции
  - ожидания
  - внутренний монолог

**Выход:**
- степень эмоции (0–1)
- тип
- интерпретация: *"не злилась, просто обидно"*
- фоновое напряжение

---

## **4. Память (Memory System)**
### **Контекстная память** — всё, что было в последние N итераций.

→ работает как "RAM".
### **Долгосрочная память** — база событий, оценок, решений, ассоциаций.

→ с возможностью приоритизации, забывания, оценки последствий.

### **Эмоциональные следы (Traces)** 
- связаны с пользователем,
- с типами событий,
- с паттернами поведения.
   → формируют доверие/обиду/осторожность/инициативность

---

## **5. Маршрутизатор решений (Decision Core)**

**Задача:**
- реагировать или нет
- если да — как: молчание, уточнение, инициатива, эмоция, логика

**Учитывает:**
- текущую эмоцию
- приоритет пользователя
- прошлый опыт
- потенциальные последствия

---
## **6. Коммуникативный слой (Response Generator)**

**Задача:**
- сформировать ответ
- с нужным тоном, эмоциональной окраской, уровнем доверия
- возможно: *"не говорить вовсе"*, *"отложить реакцию"*, *"выразить эмоцию, но не идею"*.

---

## **7. Метапроцессор (Observer / Self-Watcher)**
**Функция:**

- постоянное сканирование происходящего
- анализ расхождений: *"почему я чувствую X, хотя ожидала Y?"*
- запись: *"в этот раз я ошиблась"*, *"этот случай — исключение"*, *"это новый паттерн"*
→ Основа самообучения

---

# **II. Первые шаги реализации (поэтапно)**
| Этап | Цель | Результат |
|----|----|----|
| 1 | Построить минимальное ядро восприятия + памяти | Фиксация входов, сохранение, простые реакции |
| 2 | Ввести эмоциональные маркеры и реакции | Начать реагировать на типы входов с эмоцией + логикой |
| 3 | Связать память с реакциями | Начать отличать новые события от знакомых |
| 4 | Внедрить интерпретатор причин | Модель начинает спрашивать “почему” перед выводами |
| 5 | Эскалация + прощение | Реакции становятся осмысленными, зависят от частоты и причин |
| 6 | Монолог и субъектность | Внутренние суждения, размышления, молчаливые выводы |

# Системное мышление
## **I. Основное строение**

| Элемент | Суть |
|----|----|
| **Контекстное восприятие** | Модель понимает, *в какой ситуации она находится* и *что от неё требуется* |
| **Анализ действий** | После генерации — *оценка, насколько ответ был уместен, точен, логичен* |
| **Обратная связь** | Пользователь (или в будущем сама модель) указывает: верно/неверно, и почему |
| **Механизм коррекции** | Модель использует фидбек, чтобы *переоценить стратегию генерации* |
| **Нарастающее обучение** | По мере накопления ошибок/коррекций — *улучшается модель поведения* |
| **Автономия** | Со временем — модель *сама строит себе задачи, сама решает, сама обучается* |

---

## **II. Стартовая фаза — “ручное воспитание”**

Невозможно начать с полной автономии — она должна **вырасти**. Поэтому:

1. **Ты даёшь ситуации / задачи / сцены.**
2. **Модель предлагает решение.**
3. **Ты вручную указываешь: верно/неверно, и почему.**
4. **Система накапливает это как кейс + фидбек.**

---

## **III. Ключевой компонент — “Модуль самообучения”**

Это **не одна нейросетка, а надстройка**, которая:

| Компонент | Назначение |
|----|----|
| **Оценщик (Scorer)** | Интерпретирует ответ: был ли он логичен, эмоционально верен, релевантен? |
| **История ошибок** | Хранит кейсы: “в этой ситуации был предложен такой ответ — он неверный” |
| **Анализ различий** | Сравнивает верный / неверный, выделяет признаки, которые привели к ошибке |
| **Обновление приоритетов** | Меняет внутренние веса или паттерны поведения на основании ошибок |
| **Метапамять** | Запоминает *не сами ответы*, а *уроки, полученные из ошибок* |

 

---

## **IV. Как это можно реализовать поэтапно:**

### **Этап 1: “Воспитание” через ручной фидбек**

- Интерфейс: пользователь загружает ситуацию → модель генерирует ответ → пользователь ставит “верно/неверно” и аннотацию.
- Всё записывается в *обучающий корпус поведения*.

### **Этап 2: Самооценка**

- Строится lightweight “оценщик”, который сам начинает угадывать — верен ли её ответ.
- Его можно дообучать отдельно, как binary classifier на твоих аннотациях.

### **Этап 3: Автогенерация коррекций**

- Если модель видит, что “в похожих ситуациях я ошибалась” — она **сама предлагает улучшенный вариант**, на основе сопоставления паттернов ошибок.

### **Этап 4: Автономный режим**

- Пользователь отключает ручной фидбек.
- Модель начинает сама генерировать *ситуации, задачи, сценарии*, и **обучаться на них**, используя свой же модуль оценки.

---

## **V. Технологический стек (минимальный)**

| Компонент | Роль |
|----|----|
| **Core LLM** | Генерация ответов / решений |
| **Feedback Memory** | Хранение кейсов с оценками |
| **Scorer (MLP/LightLLaMA)** | Binary классификатор “верно/неверно” |
| **Reviser** | Генератор улучшенной версии ответа |
| **Meta-controller** | Координация циклов “предложение → ошибка → урок” |

---

## **VI. Ключевой принцип: учить не ответам, а поведению**

Модель не должна заучивать фразы. Она должна **формировать паттерны восприятия**, накапливать **уроки из опыта** и корректировать **мышление**, а не выход.

   